{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9183f1eef22d7eca",
   "metadata": {},
   "source": [
    "# Alcance del Notebook\n",
    "Queremos replicar el expermiento de Frank Rosenblatt, para eso, vamos a cargar un dataset con 1000 imagenes en blanco y negro en las cuales tenemos distinguidas y etiquetadas aquellas que tienen cuadrados a la izquierda y a la derecha."
   ]
  },
  {
   "cell_type": "code",
   "id": "1364c7a023a1ea6a",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "35ccde806d49af8d",
   "metadata": {},
   "source": [
    "## Carga del dataset\n",
    "Tomamos un dataset previamente creado con 1000 imágenes de 38x38 con cuadrados desde 1x1 hasta 11x11 que se encuentran completamente a derecha o izquierda. Por cada tamaño de cuadrado tenemos 10 de cada tipo."
   ]
  },
  {
   "cell_type": "code",
   "id": "43910e893613b7",
   "metadata": {},
   "source": [
    "tfrecord_zip = \"https://drive.google.com/u/0/uc?id=1AtgJa4sE0PeI-ooy5eBvSETxr1kIYt0A&export=download\"\n",
    "\n",
    "dest_path = os.path.join(os.path.curdir, 'data')\n",
    "file_name = 'dataset.zip'\n",
    "file_path = os.path.join(os.path.curdir, file_name)\n",
    "\n",
    "response = requests.get(tfrecord_zip)\n",
    "with open(file_path, 'wb') as dest_file:\n",
    "    dest_file.write(response.content)\n",
    "\n",
    "# Descomprimimos el archivo ZIP\n",
    "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(dest_path)\n",
    "\n",
    "# Cargamos el dataset desde el archivo TFRecord para despues poder manipularlo con TensorFlow\n",
    "dataset = tf.data.Dataset.load('/content/rosenblatt_sample.tfrecord')\n",
    "# Mezclamos las imagenes de forma azarosa, pero con un seed para que siempre sea el mismo azar y podamos hacer pruebas determinísticas\n",
    "dataset = dataset.shuffle(1000, seed=17, reshuffle_each_iteration=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8967865723e5b65a",
   "metadata": {},
   "source": [
    "## Dibujamos las imágenes del Dataset (algunas)"
   ]
  },
  {
   "cell_type": "code",
   "id": "f2f2bf0d6e4b0874",
   "metadata": {},
   "source": [
    "# Definir el tamaño de la cuadrícula de subplots\n",
    "rows = 20\n",
    "columns = 5\n",
    "\n",
    "# Crear una figura y subplots\n",
    "fig, axs = plt.subplots(rows, columns, figsize=(10, 30))\n",
    "\n",
    "# Iterar a través de las imágenes y subplots\n",
    "row = 0\n",
    "column = 0\n",
    "for image, label in dataset.take(100):  # Agarramos solo 100\n",
    "  axs[row, column].imshow(image, cmap=mpl.cm.binary)\n",
    "  axs[row, column].set_title(f\"Etiqueta {int(label[0])}\")\n",
    "  axs[row, column].axis('off')  # Desactivar los ejes\n",
    "  if (column+1) % 5 == 0:\n",
    "    column = 0\n",
    "    row += 1\n",
    "  else:\n",
    "    column += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b7c021ecb99a4d2c",
   "metadata": {},
   "source": [
    "## Preparación de los datos\n",
    "Vamos a querer dividir la totalidad de muestras en subconjuntos de entrenamiento y subconjuntos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "id": "b4c7038087f46de4",
   "metadata": {},
   "source": [
    "train_dataset = dataset.take(800)\n",
    "test_dataset = dataset.skip(800).take(200)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "71527d9756aaf509",
   "metadata": {},
   "source": [
    "## Normalización\n",
    "Al trabajar con imagenes una práctica comun es representar la imagen como un vector de una sola dimensión, entonces en lugar de una matriz de 38x38 vamos a contar con vectores de 1444 valores. Esto es útil para realizar operaciones de manera mas sencilla e intuitiva. Otra acción que tomamos y también es práctica habitual es representar los colores en escalas entre 1 y 0."
   ]
  },
  {
   "cell_type": "code",
   "id": "7bb95cc3696263af",
   "metadata": {},
   "source": [
    "def normalize(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "# Transforma la imagen un único vector fila de 784 elementos\n",
    "def flatten(image, label):\n",
    "    image = tf.reshape(image, shape=[1, -1])\n",
    "    return image, label\n",
    "\n",
    "def preprocess_pipeline(dataset_to_process):\n",
    "    dataset_to_process = dataset_to_process.map(normalize)\n",
    "    dataset_to_process = dataset_to_process.map(flatten)\n",
    "    return dataset_to_process\n",
    "\n",
    "train_dataset = preprocess_pipeline(train_dataset)\n",
    "test_dataset = preprocess_pipeline(test_dataset)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2def28a9098afa51",
   "metadata": {},
   "source": [
    "## Ahora si, a entrenar!\n",
    "Habitualmente se setea una cantidad de \"epocas\" en las que un modelo debe entrenar de forma iterativa.\n",
    "\n",
    "Para este problema particular, nos interesa ir moviendonos por la gradiente a medida que nuestra neurona va arrojando resultados para cada entrada. Si bien esto\n",
    "parece complejo, herramientas como TensorFlow vienen a salvarnos para no tener que pensar tan fuertemente en la parte matemática del asunto.\n",
    "\n",
    "Como parte del algoritmo, tenemos que ver cuales son nuestras funciones de activación y de pérdida. Nuevamente para este problema se conoce que las funciones son:\n",
    "\n",
    "Funcion Sigmoide (Activación)\n",
    "$$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "\n",
    "Binary Cross Entropy (Pérdida)\n",
    "$$ H(true\\_val, predict) = - (true\\_val \\log(predict) + (1 - true\\_val) \\log(1 - predict))$$\n",
    "\n",
    "No queda mas que programar el algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "id": "a2762af18e702a7",
   "metadata": {},
   "source": [
    "# Nuevamente tomamos un random seedeado para poder replicar el mismo entrenamiento en futuras interacciones\n",
    "tf.random.set_seed(234)\n",
    "\n",
    "w = tf.zeros(shape=[1444,1])\n",
    "b = tf.zeros(shape=[])\n",
    "w = tf.Variable(w)\n",
    "b = tf.Variable(b)\n",
    "\n",
    "model_variables = [w, b]\n",
    "\n",
    "epochs = 25  # Seteamos las épocas para \"entrenar\"\n",
    "learning_rate = 0.005\n",
    "# Data de output:\n",
    "train_losses = []\n",
    "train_accuracy = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_accuracies = []\n",
    "    epoch_losses = []\n",
    "    epoch_test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Iteración sobre los conjuntos de entrenamiento\n",
    "        for image, true_label in train_dataset.take(800):\n",
    "            # Primero obtenemos del dataset el valor que quermos predecir,\n",
    "            # o sea, la etiqueta que indica si es derecha o izquierda.\n",
    "            # Lo casteamos a float ya que lo tenemos almacenado como un entero\n",
    "            # dentro de un arreglo de dimension 1.\n",
    "            true_label = tf.cast(true_label[0], tf.float32)\n",
    "            # Aplicamos la ecuacion 'y = w*x + b', pero en vectores:\n",
    "            # logits = w*image + b\n",
    "            logits = tf.add(tf.matmul(image, w), b)\n",
    "            # Dentro de logits podemos tener cualquier valor flotante y ademas\n",
    "            # la operacion realizada con tf retorna este valor como un arreglo de arreglos.\n",
    "            # Por eso usamos squeeze que solamente le quita una dimension.\n",
    "            logits = tf.squeeze(logits)\n",
    "            # aplicamos sigmoide a logits para tenerlo entre 0 y 1 y calculamos\n",
    "            # la perdida respecto de true_label usando binary_cross_entropy\n",
    "            loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=true_label, logits=logits)\n",
    "            epoch_losses.append(loss)\n",
    "\n",
    "            # Calculamos el accuracy de nuestra prediccion y guardamos\n",
    "            prediction = 1.0 if tf.math.sigmoid(logits)>0.5 else 0.0\n",
    "            accuracy = 1.0 if prediction == true_label else 0.0\n",
    "            epoch_accuracies.append(accuracy)\n",
    "\n",
    "        epoch_accuracies_mean = tf.reduce_mean(epoch_accuracies)\n",
    "        # Computamos el gradiente de la funcion de perdida a minimizar\n",
    "        epoch_losses_mean = tf.reduce_mean(epoch_losses)\n",
    "    # Obtenemos el gradiente para minimizar la funcion de perdida\n",
    "    grads = tape.gradient(epoch_losses_mean, model_variables)\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    print(f\"Loss: {epoch_losses_mean:.3f}\")\n",
    "    print(f\"Accuracy: {epoch_accuracies_mean:.3f}\")\n",
    "\n",
    "    # Actualizamos el modelo moviendo w y b en direccion del gradiente\n",
    "    # en la cantidad indicada por nuestro learning_rate.\n",
    "    for dv, variable in zip(grads, model_variables):\n",
    "        variable.assign_sub(learning_rate * dv)\n",
    "\n",
    "    train_losses.append(epoch_losses_mean)\n",
    "\n",
    "    # Iteración sobre los conjuntos de validación\n",
    "    for image, true_label in test_dataset.take(200):\n",
    "      true_label = tf.cast(true_label[0], tf.float32)\n",
    "      logits = tf.add(tf.matmul(image, w), b)\n",
    "      logits = tf.squeeze(logits)\n",
    "      loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=true_label, logits=logits)\n",
    "      epoch_test_losses.append(loss)\n",
    "\n",
    "      prediction = 1.0 if tf.math.sigmoid(logits)>0.5 else 0.0\n",
    "      accuracy = 1.0 if prediction == true_label else 0.0\n",
    "      test_accuracies.append(accuracy)\n",
    "\n",
    "    test_accuracies_mean = tf.reduce_mean(test_accuracies)\n",
    "\n",
    "    # keep track of the loss\n",
    "    test_epoch_losses_mean = tf.reduce_mean(epoch_test_losses)\n",
    "    test_losses.append(test_epoch_losses_mean)\n",
    "    print(f\"Test loss: {test_epoch_losses_mean:.3f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracies_mean:.3f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "# Función que representa al modelo entrenado, dado una imagen de las mismas condiciones, devuelve si el cuadrado está a la derecha o izquierda\n",
    "def predict(image):\n",
    "  logits = tf.add(tf.matmul(image, w), b)\n",
    "  logits = tf.squeeze(logits)\n",
    "  return \"Derecha\" if tf.math.sigmoid(logits)>0.5 else \"Izquierda\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "24ad67450549a14f",
   "metadata": {},
   "source": [
    "# Wait... como le creo al modelo?\n",
    "Adicionalmente, creamos un set de funciones que nos va a permitir crear imagenes con cuadrados de las mismas características, luego le pasamos esta imagen al modelo y lo ponemos a prueba!"
   ]
  },
  {
   "cell_type": "code",
   "id": "56d950763bbc3afa",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Variable para almacenar la imagen resultante\n",
    "image_to_predict = None\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "def draw_square(pos_x, pos_y, size):\n",
    "    global image_to_predict\n",
    "    # Crear una imagen en blanco y negro\n",
    "    imagen = np.zeros((38, 38), dtype=np.uint8)\n",
    "    # Dibujar un cuadrado blanco en la posición y tamaño especificados\n",
    "    imagen[pos_y:pos_y + size, pos_x:pos_x + size] = 1\n",
    "    # Mostrar la imagen\n",
    "    plt.imshow(imagen, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    image_to_predict =1.0 - imagen.reshape(1, -1).astype(np.float32)\n",
    "    plt.close()\n",
    "\n",
    "# Campos interactivos\n",
    "pos_x = widgets.IntSlider(min=0, max=38, step=1, value=0, description='pos_x:')\n",
    "pos_y = widgets.IntSlider(min=0, max=38, step=1, value=0, description='pos_y:')\n",
    "size = widgets.IntSlider(min=1, max=38, step=1, value=10, description='size:')\n",
    "\n",
    "# Botón para dibujar el cuadrado\n",
    "draw_button = widgets.Button(description='Dibujar Cuadrado')\n",
    "\n",
    "# Función para manejar el clic en el botón\n",
    "def on_button_click(b):\n",
    "  draw_square(pos_x.value, pos_y.value, size.value)\n",
    "\n",
    "# Asociar la función con el evento de clic en el botón\n",
    "draw_button.on_click(on_button_click)\n",
    "\n",
    "# Mostrar campos y botón\n",
    "display(pos_x, pos_y, size, draw_button)\n",
    "\n",
    "# Mostrar la imagen generada (si existe)\n",
    "if image_to_predict is not None:\n",
    "    display(Image(data=image_to_predict))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3c79328a27c58e0d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "c904e414bed8d2ce",
   "metadata": {},
   "source": [
    "# Ahora, que el modelo prediga...\n",
    "predict(image_to_predict)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
